{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76667869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similaritylarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0682d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of BERT base vocabulary: 30522\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(f'The length of BERT base vocabulary: {len(tokenizer.vocab)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e767a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1037, 3722, 6251, 102]\n"
     ]
    }
   ],
   "source": [
    "text = 'A simple sentence'\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e63b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] a simple sentence [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a460a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2026, 2767, 2409, 2033, 2055, 2023, 2465, 1998, 1045, 2293, 2009, 2061, 2521, 999, 2016, 2001, 2157, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "text = 'My friend told me about this class and I love it so far! She was right.'\n",
    "tokens = tokenizer.encode(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ce6bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: My friend told me about this class and I love it so far! She was right. Num tokens: 20\n",
      "Token: 101, subword: [CLS]\n",
      "Token: 2026, subword: my\n",
      "Token: 2767, subword: friend\n",
      "Token: 2409, subword: told\n",
      "Token: 2033, subword: me\n",
      "Token: 2055, subword: about\n",
      "Token: 2023, subword: this\n",
      "Token: 2465, subword: class\n",
      "Token: 1998, subword: and\n",
      "Token: 1045, subword: i\n",
      "Token: 2293, subword: love\n",
      "Token: 2009, subword: it\n",
      "Token: 2061, subword: so\n",
      "Token: 2521, subword: far\n",
      "Token: 999, subword: !\n",
      "Token: 2016, subword: she\n",
      "Token: 2001, subword: was\n",
      "Token: 2157, subword: right\n",
      "Token: 1012, subword: .\n",
      "Token: 102, subword: [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(f'Text: {text} Num tokens: {len(tokens)}')\n",
    "for t in tokens:\n",
    "    print(f'Token: {t}, subword: {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f35b3944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 101, subword: [CLS]\n",
      "Token: 8739, subword: sake\n",
      "Token: 2102, subword: ##t\n",
      "Token: 7459, subword: loves\n",
      "Token: 1037, subword: a\n",
      "Token: 3376, subword: beautiful\n",
      "Token: 2154, subword: day\n",
      "Token: 102, subword: [SEP]\n"
     ]
    }
   ],
   "source": [
    "text_with_unknown_words = 'Saket loves a beautiful day'\n",
    "tokens_with_unknown_words = tokenizer.encode(text_with_unknown_words)\n",
    "for t in tokens_with_unknown_words:\n",
    "    print(f'Token: {t}, subword: {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e20e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 101, subword: [CLS]\n",
      "Token: 8739, subword: sake\n",
      "Token: 2102, subword: ##t\n",
      "Token: 2003, subword: is\n",
      "Token: 2256, subword: our\n",
      "Token: 9450, subword: instructor\n",
      "Token: 2005, subword: for\n",
      "Token: 2023, subword: this\n",
      "Token: 12476, subword: awesome\n",
      "Token: 23823, subword: ##sau\n",
      "Token: 3401, subword: ##ce\n",
      "Token: 2465, subword: class\n",
      "Token: 102, subword: [SEP]\n"
     ]
    }
   ],
   "source": [
    "text_with_unknown_words = 'Saket is our instructor for this awesomesauce class'\n",
    "tokens_with_unknown_words = tokenizer.encode(text_with_unknown_words)\n",
    "for t in tokens_with_unknown_words:\n",
    "    print(f'Token: {t}, subword: {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0477094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2026, 2767, 2409, 2033, 2055, 2023, 2465, 1998, 1045, 2293, 2009, 2061, 2521, 999, 2016, 2001, 2157, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "text = 'My friend told me about this class and I love it so far! She was right.'\n",
    "tokens = tokenizer.encode_plus(text)\n",
    "print(tokens)\n",
    "\n",
    "# attention_mask is 1 if included in the calculation of attention, otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1454f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be5b17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_pet = tokenizer.encode('I love my pet python')\n",
    "python_language = tokenizer.encode('I love coding in python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea5c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contextful embedding of of 'python' in 'I love my pet python'\n",
    "python_pet_embedding = model(torch.tensor(python_pet).unsqueeze(0))[0][:,5,:].detach().numpy()\n",
    "\n",
    "# contextful embedding of of 'python' in 'I love coding in python'\n",
    "python_language_embedding = model(torch.tensor(python_language).unsqueeze(0))[0][:,5,:].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22954d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contextful embedding of 'snake' in 'snake'\n",
    "snake_alone_embedding = model(torch.tensor(tokenizer.encode('snake')).unsqueeze(0))[0][:,1,:].detach().numpy()\n",
    "\n",
    "# contextful embedding of 'programming' in 'programming'\n",
    "programming_alone_embedding = model(torch.tensor(tokenizer.encode('programming')).unsqueeze(0))[0][:,1,:].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "819ddb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5843477]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about coding to the word snake\n",
    "cosine_similarity(python_language_embedding, snake_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "843b08b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6928658]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about pets to the word snake\n",
    "cosine_similarity(python_pet_embedding, snake_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6733d2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.498644]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about coding to the word programming\n",
    "cosine_similarity(python_pet_embedding, programming_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85192445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5614743]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about coding to the word programming\n",
    "cosine_similarity(python_language_embedding, programming_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d894e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
